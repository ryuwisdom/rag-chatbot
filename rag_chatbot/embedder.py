# rag_chatbot/embedder.py

from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_huggingface import  HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
import os

from torch.fx.passes.dialect.common.cse_pass import rand_ops


def create_chunks(text: str, chunk_size: int = 1500, chunk_overlap: int = 200):
    """í…ìŠ¤íŠ¸ë¥¼ chunk ë‹¨ìœ„ë¡œ ë‚˜ëˆ”"""
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        separators=["\n\n", "\n", ".", " "]
    )
    return splitter.create_documents([text])

# ë¬¸ì„œ ì¡°ê°ë“¤(chunks)ê³¼ ìž„ë² ë”© ëª¨ë¸(embedding_model)ì„ ë°›ì•„ì„œ, ë²¡í„°ë¡œ ë³€í™˜í•œ ë’¤, FAISS ë²¡í„° ì €ìž¥ì†Œë¥¼ ë§Œë“¤ì–´ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
def create_vector_store(chunks, embedding_model) -> FAISS:
    print("ðŸ“¥ chunks received:", len(chunks))
    print("ðŸ“¦ creating FAISS vector store...")
    vector_store = FAISS.from_documents(chunks, embedding_model)
    return vector_store



def load_vector_store():
    persist_directory = "vectorstore"
    if not os.path.exists(persist_directory):
        raise FileNotFoundError(f"Vector store not found at {persist_directory}")

    embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    return FAISS.load_local(persist_directory, embedding_model, allow_dangerous_deserialization=True )

# def load_pdf(pdf_path: str) -> str:
#     loader = PyPDFLoader(pdf_path)
#     document = loader.load()
#     text = " ".join([doc.page_content for doc in document])
#     return text